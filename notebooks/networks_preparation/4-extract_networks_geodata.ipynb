{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411aa7cf-25ea-40e5-8d97-64408077cad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping install of 'rmangal' from a github remote, the SHA1 (87df6fd8) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remotes::install_github(\"ropensci/rmangal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b56829-9d0f-47bf-b603-9c392369eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.1     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.4     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 1.0.0\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Linking to GEOS 3.10.2, GDAL 3.5.0, PROJ 9.0.0; sf_use_s2() is TRUE\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "\n",
      "Attaching package: ‘raster’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(dplyr)\n",
    "library(sf)\n",
    "library(rmangal)\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948b6439-2dbf-45e8-b09b-c8267310abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_metadata_path = \"../../data/networks/all/networks_metadata.csv\"\n",
    "\n",
    "rmangal_observations_data_path = \"../../data/networks/parsed_rmangal_networks_metadata.csv\"\n",
    "rmangal_metadata_path = \"../../data/networks/all_rmangal_networks.csv\"\n",
    "\n",
    "ecoregion_polygon_data_path = \"../../data/networks/metadata/polygon/wwf_terr_ecos.shp\"\n",
    "\n",
    "temp_input_for_bioclim_path = \"../../data/networks/all/geo_avail_networks_metadata.csv\"\n",
    "temp_output_for_bioclim_path = \"../../data/networks/all/geo_extracted_networks_metadata.csv\"\n",
    "bioclim_dir = \"../../data/networks/metadata/bioclimate/\"\n",
    "richness_data_path = \"../../data/networks/metadata/Richness_2021.tif\"\n",
    "rmangal_geodata_path = \"../../data/networks/rmangal_networks_geodata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4a331-fb22-47b3-a3ac-6d1da2a9d4cb",
   "metadata": {},
   "source": [
    "# get geodata for networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd90d0-13a7-4861-b66e-d2769f338142",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mangal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3c1a6-c3ad-4653-be69-9eaae57b0756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`type` used, `query` ignored.\n",
      "\n",
      "Data retrieval 0.279%   \n",
      "Data retrieval 0.557%   \n",
      "Data retrieval 0.836%   \n",
      "Data retrieval 1.11%   \n",
      "Data retrieval 1.39%   \n",
      "Data retrieval 1.67%   \n",
      "Data retrieval 1.95%   \n",
      "Data retrieval 2.23%   \n",
      "Data retrieval 2.51%   \n",
      "Data retrieval 2.79%   \n",
      "Data retrieval 3.06%   \n",
      "Data retrieval 3.34%   \n",
      "Data retrieval 3.62%   \n",
      "Data retrieval 3.9%   \n",
      "Data retrieval 4.18%   \n",
      "Data retrieval 4.46%   \n",
      "Data retrieval 4.74%   \n",
      "Data retrieval 5.01%   \n",
      "Data retrieval 5.29%   \n",
      "Data retrieval 5.57%   \n",
      "Data retrieval 5.85%   \n",
      "Data retrieval 6.13%   \n",
      "Data retrieval 6.41%   \n",
      "Data retrieval 6.69%   \n",
      "Data retrieval 6.96%   \n",
      "Data retrieval 7.24%   \n",
      "Data retrieval 7.52%   \n",
      "Data retrieval 7.8%   \n",
      "Data retrieval 8.08%   \n",
      "Data retrieval 8.36%   \n",
      "Data retrieval 8.64%   \n",
      "Data retrieval 8.91%   \n",
      "Data retrieval 9.19%   \n",
      "Data retrieval 9.47%   \n",
      "Data retrieval 9.75%   \n",
      "Data retrieval 10%   \n",
      "Data retrieval 10.3%   \n",
      "Data retrieval 10.6%   \n",
      "Data retrieval 10.9%   \n",
      "Data retrieval 11.1%   \n",
      "Data retrieval 11.4%   \n",
      "Data retrieval 11.7%   \n",
      "Data retrieval 12%   \n",
      "Data retrieval 12.3%   \n",
      "Data retrieval 12.5%   \n",
      "Data retrieval 12.8%   \n",
      "Data retrieval 13.1%   \n",
      "Data retrieval 13.4%   \n",
      "Data retrieval 13.6%   \n",
      "Data retrieval 13.9%   \n",
      "Data retrieval 14.2%   \n",
      "Data retrieval 14.5%   \n",
      "Data retrieval 14.8%   \n",
      "Data retrieval 15%   \n",
      "Data retrieval 15.3%   \n",
      "Data retrieval 15.6%   \n",
      "Data retrieval 15.9%   \n",
      "Data retrieval 16.2%   \n",
      "Data retrieval 16.4%   \n",
      "Data retrieval 16.7%   \n",
      "Data retrieval 17%   \n",
      "Data retrieval 17.3%   \n",
      "Data retrieval 17.5%   \n",
      "Data retrieval 17.8%   \n",
      "Data retrieval 18.1%   \n",
      "Data retrieval 18.4%   \n",
      "Data retrieval 18.7%   \n",
      "Data retrieval 18.9%   \n",
      "Data retrieval 19.2%   \n",
      "Data retrieval 19.5%   \n",
      "Data retrieval 19.8%   \n",
      "Data retrieval 20.1%   \n",
      "Data retrieval 20.3%   \n",
      "Data retrieval 20.6%   \n",
      "Data retrieval 20.9%   \n",
      "Data retrieval 21.2%   \n",
      "Data retrieval 21.4%   \n",
      "Data retrieval 21.7%   \n",
      "Data retrieval 22%   \n",
      "Data retrieval 22.3%   \n",
      "Data retrieval 22.6%   \n",
      "Data retrieval 22.8%   \n",
      "Data retrieval 23.1%   \n",
      "Data retrieval 23.4%   \n",
      "Data retrieval 23.7%   \n",
      "Data retrieval 24%   \n",
      "Data retrieval 24.2%   \n",
      "Data retrieval 24.5%   \n",
      "Data retrieval 24.8%   \n",
      "Data retrieval 25.1%   \n",
      "Data retrieval 25.3%   \n",
      "Data retrieval 25.6%   \n",
      "Data retrieval 25.9%   \n",
      "Data retrieval 26.2%   \n",
      "Data retrieval 26.5%   \n",
      "Data retrieval 26.7%   \n",
      "Data retrieval 27%   \n",
      "Data retrieval 27.3%   \n",
      "Data retrieval 27.6%   \n",
      "Data retrieval 27.9%   \n",
      "Data retrieval 28.1%   \n",
      "Data retrieval 28.4%   \n",
      "Data retrieval 28.7%   \n",
      "Data retrieval 29%   \n",
      "Data retrieval 29.2%   \n",
      "Data retrieval 29.5%   \n",
      "Data retrieval 29.8%   \n",
      "Data retrieval 30.1%   \n",
      "Data retrieval 30.4%   \n",
      "Data retrieval 30.6%   \n",
      "Data retrieval 30.9%   \n",
      "Data retrieval 31.2%   \n",
      "Data retrieval 31.5%   \n",
      "Data retrieval 31.8%   \n",
      "Data retrieval 32%   \n",
      "Data retrieval 32.3%   \n",
      "Data retrieval 32.6%   \n",
      "Data retrieval 32.9%   \n",
      "Data retrieval 33.1%   \n",
      "Data retrieval 33.4%   \n",
      "Data retrieval 33.7%   \n",
      "Data retrieval 34%   \n",
      "Data retrieval 34.3%   \n",
      "Data retrieval 34.5%   \n",
      "Data retrieval 34.8%   \n",
      "Data retrieval 35.1%   \n",
      "Data retrieval 35.4%   \n",
      "Data retrieval 35.7%   \n",
      "Data retrieval 35.9%   \n",
      "Data retrieval 36.2%   \n",
      "Data retrieval 36.5%   \n",
      "Data retrieval 36.8%   \n",
      "Data retrieval 37%   \n",
      "Data retrieval 37.3%   \n",
      "Data retrieval 37.6%   \n",
      "Data retrieval 37.9%   \n",
      "Data retrieval 38.2%   \n",
      "Data retrieval 38.4%   \n",
      "Data retrieval 38.7%   \n",
      "Data retrieval 39%   \n",
      "Data retrieval 39.3%   \n",
      "Data retrieval 39.6%   \n",
      "Data retrieval 39.8%   \n",
      "Data retrieval 40.1%   \n",
      "Data retrieval 40.4%   \n",
      "Data retrieval 40.7%   \n",
      "Data retrieval 40.9%   \n",
      "Data retrieval 41.2%   \n",
      "Data retrieval 41.5%   \n",
      "Data retrieval 41.8%   \n",
      "Data retrieval 42.1%   \n",
      "Data retrieval 42.3%   \n",
      "Data retrieval 42.6%   \n",
      "Data retrieval 42.9%   \n",
      "Data retrieval 43.2%   \n",
      "Data retrieval 43.5%   \n",
      "Data retrieval 43.7%   \n",
      "Data retrieval 44%   \n",
      "Data retrieval 44.3%   \n",
      "Data retrieval 44.6%   \n",
      "Data retrieval 44.8%   \n",
      "Data retrieval 45.1%   \n",
      "Data retrieval 45.4%   \n",
      "Data retrieval 45.7%   \n",
      "Data retrieval 46%   \n",
      "Data retrieval 46.2%   \n",
      "Data retrieval 46.5%   \n",
      "Data retrieval 46.8%   \n",
      "Data retrieval 47.1%   \n",
      "Data retrieval 47.4%   \n",
      "Data retrieval 47.6%   \n",
      "Data retrieval 47.9%   \n",
      "Data retrieval 48.2%   \n",
      "Data retrieval 48.5%   \n",
      "Data retrieval 48.7%   \n",
      "Data retrieval 49%   \n",
      "Data retrieval 49.3%   \n",
      "Data retrieval 49.6%   \n",
      "Data retrieval 49.9%   \n",
      "Data retrieval 50.1%   \n",
      "Data retrieval 50.4%   \n",
      "Data retrieval 50.7%   \n",
      "Data retrieval 51%   \n",
      "Data retrieval 51.3%   \n",
      "Data retrieval 51.5%   \n",
      "Data retrieval 51.8%   \n",
      "Data retrieval 52.1%   \n",
      "Data retrieval 52.4%   \n",
      "Data retrieval 52.6%   \n",
      "Data retrieval 52.9%   \n",
      "Data retrieval 53.2%   \n",
      "Data retrieval 53.5%   \n",
      "Data retrieval 53.8%   \n",
      "Data retrieval 54%   \n",
      "Data retrieval 54.3%   \n",
      "Data retrieval 54.6%   \n",
      "Data retrieval 54.9%   \n",
      "Data retrieval 55.2%   \n",
      "Data retrieval 55.4%   \n",
      "Data retrieval 55.7%   \n",
      "Data retrieval 56%   \n",
      "Data retrieval 56.3%   \n",
      "Data retrieval 56.5%   \n",
      "Data retrieval 56.8%   \n",
      "Data retrieval 57.1%   \n",
      "Data retrieval 57.4%   \n",
      "Data retrieval 57.7%   \n",
      "Data retrieval 57.9%   \n",
      "Data retrieval 58.2%   \n",
      "Data retrieval 58.5%   \n",
      "Data retrieval 58.8%   \n",
      "Data retrieval 59.1%   \n",
      "Data retrieval 59.3%   \n",
      "Data retrieval 59.6%   \n",
      "Data retrieval 59.9%   \n",
      "Data retrieval 60.2%   \n",
      "Data retrieval 60.4%   \n",
      "Data retrieval 60.7%   \n",
      "Data retrieval 61%   \n",
      "Data retrieval 61.3%   \n",
      "Data retrieval 61.6%   \n",
      "Data retrieval 61.8%   \n",
      "Data retrieval 62.1%   \n",
      "Data retrieval 62.4%   \n",
      "Data retrieval 62.7%   \n",
      "Data retrieval 63%   \n",
      "Data retrieval 63.2%   \n",
      "Data retrieval 63.5%   \n",
      "Data retrieval 63.8%   \n",
      "Data retrieval 64.1%   \n",
      "Data retrieval 64.3%   \n",
      "Data retrieval 64.6%   \n",
      "Data retrieval 64.9%   \n",
      "Data retrieval 65.2%   \n",
      "Data retrieval 65.5%   \n",
      "Data retrieval 65.7%   \n",
      "Data retrieval 66%   \n",
      "Data retrieval 66.3%   \n",
      "Data retrieval 66.6%   \n",
      "Data retrieval 66.9%   \n",
      "Data retrieval 67.1%   \n",
      "Data retrieval 67.4%   \n",
      "Data retrieval 67.7%   \n",
      "Data retrieval 68%   \n",
      "Data retrieval 68.2%   \n",
      "Data retrieval 68.5%   \n",
      "Data retrieval 68.8%   \n",
      "Data retrieval 69.1%   \n",
      "Data retrieval 69.4%   \n",
      "Data retrieval 69.6%   \n",
      "Data retrieval 69.9%   \n",
      "Data retrieval 70.2%   \n",
      "Data retrieval 70.5%   \n",
      "Data retrieval 70.8%   \n",
      "Data retrieval 71%   \n",
      "Data retrieval 71.3%   \n",
      "Data retrieval 71.6%   \n",
      "Data retrieval 71.9%   \n",
      "Data retrieval 72.1%   \n",
      "Data retrieval 72.4%   \n",
      "Data retrieval 72.7%   \n",
      "Data retrieval 73%   \n",
      "Data retrieval 73.3%   \n",
      "Data retrieval 73.5%   \n",
      "Data retrieval 73.8%   \n",
      "Data retrieval 74.1%   \n",
      "Data retrieval 74.4%   \n",
      "Data retrieval 74.7%   \n",
      "Data retrieval 74.9%   \n",
      "Data retrieval 75.2%   \n",
      "Data retrieval 75.5%   \n",
      "Data retrieval 75.8%   \n",
      "Data retrieval 76%   \n",
      "Data retrieval 76.3%   \n",
      "Data retrieval 76.6%   \n",
      "Data retrieval 76.9%   \n",
      "Data retrieval 77.2%   \n",
      "Data retrieval 77.4%   \n",
      "Data retrieval 77.7%   \n",
      "Data retrieval 78%   \n",
      "Data retrieval 78.3%   \n",
      "Data retrieval 78.6%   \n",
      "Data retrieval 78.8%   \n",
      "Data retrieval 79.1%   \n",
      "Data retrieval 79.4%   \n",
      "Data retrieval 79.7%   \n",
      "Data retrieval 79.9%   \n",
      "Data retrieval 80.2%   \n",
      "Data retrieval 80.5%   \n",
      "Data retrieval 80.8%   \n",
      "Data retrieval 81.1%   \n",
      "Data retrieval 81.3%   \n",
      "Data retrieval 81.6%   \n",
      "Data retrieval 81.9%   \n",
      "Data retrieval 82.2%   \n",
      "Data retrieval 82.5%   \n",
      "Data retrieval 82.7%   \n",
      "Data retrieval 83%   \n",
      "Data retrieval 83.3%   \n",
      "Data retrieval 83.6%   \n",
      "Data retrieval 83.8%   \n",
      "Data retrieval 84.1%   \n",
      "Data retrieval 84.4%   \n",
      "Data retrieval 84.7%   \n",
      "Data retrieval 85%   \n",
      "Data retrieval 85.2%   \n",
      "Data retrieval 85.5%   \n",
      "Data retrieval 85.8%   \n",
      "Data retrieval 86.1%   \n",
      "Data retrieval 86.4%   \n",
      "Data retrieval 86.6%   \n",
      "Data retrieval 86.9%   \n",
      "Data retrieval 87.2%   \n",
      "Data retrieval 87.5%   \n",
      "Data retrieval 87.7%   \n",
      "Data retrieval 88%   \n",
      "Data retrieval 88.3%   \n",
      "Data retrieval 88.6%   \n",
      "Data retrieval 88.9%   \n",
      "Data retrieval 89.1%   \n",
      "Data retrieval 89.4%   \n",
      "Data retrieval 89.7%   \n",
      "Data retrieval 90%   \n",
      "Data retrieval 90.3%   \n",
      "Data retrieval 90.5%   \n",
      "Data retrieval 90.8%   \n",
      "Data retrieval 91.1%   \n",
      "Data retrieval 91.4%   \n",
      "Data retrieval 91.6%   \n",
      "Data retrieval 91.9%   \n",
      "Data retrieval 92.2%   \n",
      "Data retrieval 92.5%   \n",
      "Data retrieval 92.8%   \n",
      "Data retrieval 93%   \n",
      "Data retrieval 93.3%   \n",
      "Data retrieval 93.6%   \n",
      "Data retrieval 93.9%   \n",
      "Data retrieval 94.2%   \n",
      "Data retrieval 94.4%   \n",
      "Data retrieval 94.7%   \n",
      "Data retrieval 95%   \n",
      "Data retrieval 95.3%   \n",
      "Data retrieval 95.5%   \n",
      "Data retrieval 95.8%   \n",
      "Data retrieval 96.1%   \n",
      "Data retrieval 96.4%   \n",
      "Data retrieval 96.7%   \n",
      "Data retrieval 96.9%   \n",
      "Data retrieval 97.2%   \n",
      "Data retrieval 97.5%   \n",
      "Data retrieval 97.8%   \n",
      "Data retrieval 98.1%   \n",
      "Data retrieval 98.3%   \n",
      "Data retrieval 98.6%   \n",
      "Data retrieval 98.9%   \n",
      "Data retrieval 99.2%   \n",
      "Data retrieval 99.4%   \n",
      "Data retrieval 99.7%   \n",
      "Data retrieval 100%   \n",
      "                                                                             \n"
     ]
    }
   ],
   "source": [
    "pollination_interactions<- search_interactions(type = \"mutualism\")\n",
    "network_ids = unique(pollination_interactions$network_id)\n",
    "length(network_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeca81-f50b-4552-af97-8e0cc2230c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks_data = data.frame()\n",
    "network_metadata_dfs = list()\n",
    "num_avail = 0\n",
    "for (i in 1:length(network_ids)) #length(pollination_networks)\n",
    "{\n",
    "  if (i %% 10 == 0) \n",
    "  {\n",
    "    print(i)\n",
    "    print(num_avail)\n",
    "  }\n",
    "  networks = search_networks(list(id=nth(network_ids,i)))  %>% get_collection\n",
    "  network = networks[[1]]\n",
    "  network_data = network$network[c(\"geom_lat\", \"geom_type\", \"geom_lon\")]\n",
    "  network_ref_data = network$reference\n",
    "  network_data = bind_cols(network_data, network_ref_data)\n",
    "  network_data[[\"network_id\"]] = nth(network_ids,i)\n",
    "  network_metadata_dfs[[i]] = network_data\n",
    "  if (! is.na(network_data$geom_lon))\n",
    "  {\n",
    "    num_avail = num_avail + 1\n",
    "  }\n",
    "  network_reference = network$reference %>% pull (doi)\n",
    "  node_data =  network$nodes %>% select (node_id,node_name = (original_name)) #original_name\n",
    "  curr_network_data = network$interactions %>% select (network_id,node_from, node_to,value,date,attribute.name,) %>% inner_join(node_data, by = c(\"node_from\" = \"node_id\"  )) %>% rename (node_from_name = node_name   ) %>% inner_join(node_data, by = c(\"node_to\" = \"node_id\"  )) %>% rename (node_to_name = node_name   ) %>% group_by(network_id,node_from_name,node_to_name) %>% summarise(total_interactions = sum(value)) %>% mutate(doi = network_reference, loop_i = i)\n",
    "}\n",
    "all_networks_data  = bind_rows(all_networks_data,curr_network_data)\n",
    "# network_metadata_df = do.call(rbind, network_metadata_dfs)\n",
    "write_csv(all_networks_data,rmangal_metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8497a7-a128-457c-9620-931efc88abaa",
   "metadata": {},
   "source": [
    "## run the  python code in notebook 5-parse_networks_geodata, under section \"unite parsed data to all networks metadata\" to merge the parsed data to the all networks metadata path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e11e8-1c59-4614-94ac-6859ad3a70e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Web of life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "edd0ecc5-8fa9-413f-a5fb-c9f82686ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url <- \"https://www.web-of-life.es/\"\n",
    "networks_metadata = read.csv(networks_metadata_path)\n",
    "non_wol_networks_metadata = networks_metadata[networks_metadata$source != \"web_of_life\", ] \n",
    "wol_networks_metadata = networks_metadata[networks_metadata$source == \"web_of_life\", ][c('network_type','network_index','path','source','is_legal','is_resolved','processed_path','is_parsed_legal')]                                                                                      \n",
    "all_nw_info <- read.csv(paste0(base_url,\"get_network_info.php\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "710fff27-4c0d-4737-a22d-68dedc0cde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name <- function(path)\n",
    "{\n",
    "    path_name = basename(path)\n",
    "    name = unlist(strsplit(path_name, \".\", fixed=TRUE))[1]\n",
    "    return (name)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c886eab7-3604-4644-9bb3-b2cfc9a2daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wol_networks_metadata$network_name = unlist(lapply(wol_networks_metadata$path,get_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52ca2d36-0820-4806-82b4-0fed199468f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nw_info$Latitude <- all_nw_info$latitude\n",
    "all_nw_info$Longitude <- all_nw_info$longitude\n",
    "\n",
    "drops <- c(\"network_type\",\"number_components\", \"is_weighted\", \"cell_values_description\", \"abundance_description\", \"latitude\", \"longitude\")\n",
    "all_nw_info = all_nw_info[ , !(names(all_nw_info) %in% drops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5ed20bc-b326-49e6-bde6-d8c328295c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'network_name'</li><li>'author'</li><li>'reference'</li><li>'location'</li><li>'location_address'</li><li>'country'</li><li>'Latitude'</li><li>'Longitude'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'network\\_name'\n",
       "\\item 'author'\n",
       "\\item 'reference'\n",
       "\\item 'location'\n",
       "\\item 'location\\_address'\n",
       "\\item 'country'\n",
       "\\item 'Latitude'\n",
       "\\item 'Longitude'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'network_name'\n",
       "2. 'author'\n",
       "3. 'reference'\n",
       "4. 'location'\n",
       "5. 'location_address'\n",
       "6. 'country'\n",
       "7. 'Latitude'\n",
       "8. 'Longitude'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"network_name\"     \"author\"           \"reference\"        \"location\"        \n",
       "[5] \"location_address\" \"country\"          \"Latitude\"         \"Longitude\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(all_nw_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "375382e7-fc7b-4c08-94a6-47a8747408a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wol_networks_metadata <- left_join(wol_networks_metadata, all_nw_info, by = join_by(network_name == network_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b4014b7-466c-41d0-b165-3ae294844026",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_networks_metdata =  networks_metadata[networks_metadata$source != \"web_of_life\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4b4aa498-18e7-4f1e-85fb-e5a5b3babe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_metadata = bind_rows(wol_networks_metadata, rest_networks_metdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc8c5d38-a7bc-4d71-9c13-826354b410cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(networks_metadata, networks_metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338f643-e125-4669-b921-dd671f4979cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# get bioclimate data for networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbb39488-0f40-4137-a776-1b86dcf86a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_metadata = read.csv(networks_metadata_path)\n",
    "relevant_network_metadata = networks_metadata[!is.na(networks_metadata$Latitude) & !is.na(networks_metadata$Longitude), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6e03d866-b749-4f96-a50b-ff8c9d173ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_network_metadata[\"ID\"] = c(1:dim(relevant_network_metadata)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4877f6-4d95-4ee0-9d4a-f047966b51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(relevant_network_metadata, in_temp_input_for_bioclim_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a3839-d70a-41cc-ae85-c23bfb1473e6",
   "metadata": {},
   "source": [
    "## run the following via windows (does not work in ppn conda env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "30d152c2-f535-483b-9095-6eeaa5168ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading layer `wwf_terr_ecos' from data source \n",
      "  `/groups/itay_mayrose/halabikeren/plant_pollinator_networks/data/networks/metadata/polygon/wwf_terr_ecos.shp' \n",
      "  using driver `ESRI Shapefile'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, :\n",
      "“GDAL Error 1: PROJ: proj_identify: Open of /groups/itay_mayrose/halabikeren/miniconda3/envs/ppn/share/proj failed”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature collection with 14458 features and 21 fields\n",
      "Geometry type: POLYGON\n",
      "Dimension:     XY\n",
      "Bounding box:  xmin: -180 ymin: -89.89197 xmax: 180 ymax: 83.62313\n",
      "Geodetic CRS:  WGS 84\n"
     ]
    }
   ],
   "source": [
    "# Load the data -----------------------------------------------------------\n",
    "#--#Observation points (NEED columns \"ID\", \"Latitude\", \"Longitude\") #--# \n",
    "Observations = rad_csv(in_temp_input_for_bioclim_path)\n",
    "\n",
    "#--#Ecoregion Polygon #--# \n",
    "Ecoregion_Polygon = st_read(ecoregion_polygon_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "76bc0388-3278-4810-a1ba-a8b74679540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--#BioClim Data #--# \n",
    "my_path = bioclim_dir\n",
    "BioClim_list = list.files(path = my_path, \n",
    "                          pattern = \".tif$\", \n",
    "                          all.files = TRUE, \n",
    "                          full.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d71639a-b515-4d76-bc86-c1c6c77c3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load rasters (Should create a list of 19)\n",
    "BioClim_Rasters = lapply(paste(my_path, \n",
    "                               BioClim_list,\n",
    "                               sep = \"\"),\n",
    "                         raster)\n",
    "  \n",
    "#--#Remover superfluous data #--# \n",
    "rm(my_path, BioClim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c495751-8b62-4565-a948-424ffcfcb758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1526"
      ],
      "text/latex": [
       "1526"
      ],
      "text/markdown": [
       "1526"
      ],
      "text/plain": [
       "[1] 1526"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#--#Regional Species Richness Data #--# \n",
    "Richness_Rasters = raster(richness_data_path)\n",
    "\n",
    "#To check that the rest of the polygons are good, you can do the following\n",
    "which(st_is_valid(Ecoregion_Polygon) != TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6c7a56a0-9b93-47ac-8d1a-6ae30aa57b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "integer(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the Ecoregion Data ----------------------------------------------\n",
    "#For whatever region, the polygon in row 1526 is not good and will cause the whole thing to mess up.\n",
    "#But since your data probably doesn't care about this you can just remove it \n",
    "#Info about the bad polygon:\n",
    "  #OBJECT_ID = 1501\n",
    "  #ECO_ID = 60125\n",
    "  #ECO_NAME = Guianan moist forests\n",
    "  #You can see the location of the region here: https://dopa-explorer.jrc.ec.europa.eu/ecoregion/60125\n",
    "#Remove the bad polygon\n",
    "Ecoregion_Polygon = Ecoregion_Polygon[-1526, ]\n",
    "\n",
    "#To check that the rest of the polygons are good, you can do the following\n",
    "which(st_is_valid(Ecoregion_Polygon) != TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0a2313c7-52fd-4723-81f2-6e6390cd73be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in CPL_crs_from_input(x):\n",
      "“GDAL Error 1: PROJ: proj_create_from_database: Open of /groups/itay_mayrose/halabikeren/miniconda3/envs/ppn/share/proj failed”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in st_transform.sfc(st_geometry(x), crs, ...): cannot transform sfc object with missing crs\n",
     "output_type": "error",
     "traceback": [
      "Error in st_transform.sfc(st_geometry(x), crs, ...): cannot transform sfc object with missing crs\nTraceback:\n",
      "1. st_transform(Observation_SF, crs = st_crs(Ecoregion_Polygon))",
      "2. st_transform.sf(Observation_SF, crs = st_crs(Ecoregion_Polygon))",
      "3. st_transform(st_geometry(x), crs, ...)",
      "4. st_transform.sfc(st_geometry(x), crs, ...)",
      "5. stop(\"cannot transform sfc object with missing crs\")"
     ]
    }
   ],
   "source": [
    "# Prepare Observation Points ----------------------------------------------\n",
    "#Convert the Observation data to an SF object\n",
    "Observation_SF = Observations %>%\n",
    "                   st_as_sf(coords = c(\"Longitude\", \n",
    "                                       \"Latitude\"))\n",
    "  \n",
    "#Give the observations the coordinate system it is referenced in (#This is dataset specific, if from GBIF use this number)\n",
    "st_crs(Observation_SF) = 4326 \n",
    "  \n",
    "#Set the coordinate system of the observations to be the same as the Polygona\n",
    "Observation_SF = st_transform(Observation_SF,\n",
    "                          crs = st_crs(Ecoregion_Polygon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437de11-ed1c-4f0a-843e-2ea9560dcce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect Points and Polygon --------------------------------------------\n",
    "#NOTE THAT DEPENDING ON YOUR DATA NOT ALL POINTS MAY INTERSECT WITH AN ECOREGION\n",
    "#Determine which polygon each point is in\n",
    "sf_use_s2(FALSE)\n",
    "Intersection_Data = as.data.frame(st_intersects(Observation_SF, Ecoregion_Polygon))\n",
    "\n",
    "#Convert the row.ID to the observation ID\n",
    "Intersection_Data$Obs_ID = Observations$ID[Intersection_Data$row.id]\n",
    "  \n",
    "#Convert the col.ID to the ecoregion ID\n",
    "Intersection_Data$EcoRegion = Ecoregion_Polygon$ECO_ID[Intersection_Data$col.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a4087c-0221-439d-aa84-3140407b91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect Points and BioClim Rasters ------------------------------------\n",
    "#Determine the raster values of each point (I do this individually to make sure no errors occur)\n",
    "\n",
    "#Create a holder\n",
    "BioClim_data = as.data.frame(matrix(nrow = nrow(Observations),\n",
    "                                    ncol = length(BioClim_Rasters) +1))\n",
    "\n",
    "#Set the column names\n",
    "colnames(BioClim_data) = c(\"Obs_ID\",\n",
    "                            paste(\"BioClim_\",\n",
    "                                1:19,\n",
    "                                sep = \"\"))\n",
    "  \n",
    "#Set the observation ID\n",
    "BioClim_data$Obs_ID = Observations$ID\n",
    "  \n",
    "#Go through each raster\n",
    "for (i in 1:length(BioClim_Rasters)) \n",
    "{\n",
    "  #Extract values and place in holder\n",
    "  BioClim_data[, i+1] = extract(BioClim_Rasters[[1]], Observation_SF)\n",
    "}\n",
    "  \n",
    "\n",
    "#Add the data to the Intersection_Data for those whose ID match\n",
    "Complete_Data = merge(Intersection_Data[, c(\"Obs_ID\", \"EcoRegion\")], \n",
    "                      BioClim_data,\n",
    "                      by.x = \"Obs_ID\",\n",
    "                      by.y = \"Obs_ID\")\n",
    "```\n",
    "\n",
    "```{r}\n",
    "#Create a holder\n",
    "richness_data = as.data.frame(matrix(nrow = nrow(Observations),\n",
    "                                    ncol = length(Richness_Rasters) +1))\n",
    "\n",
    "#Set the column names\n",
    "colnames(richness_data) = c(\"Obs_ID\",\n",
    "                            \"species_richness\")\n",
    "\n",
    "#Set the observation ID\n",
    "richness_data$Obs_ID = Observations$ID\n",
    "  \n",
    "#Go through each raster\n",
    "richness_data[[\"species_richness\"]] = extract(Richness_Rasters, Observation_SF)\n",
    "  \n",
    "\n",
    "#Add the data to the Intersection_Data for those whose ID match\n",
    "Richness_Complete_Data = merge(Intersection_Data[, c(\"Obs_ID\", \"EcoRegion\")], \n",
    "                      richness_data,\n",
    "                      by.x = \"Obs_ID\",\n",
    "                      by.y = \"Obs_ID\")\n",
    "Richness_Complete_Data <- Richness_Complete_Data[c(\"Obs_ID\", \"EcoRegion\", \"species_richness\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5c5bcf06-119c-4585-8038-d01ddf0a61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "full_data = merge(Complete_Data, \n",
    "                  Richness_Complete_Data,\n",
    "                  by.x = \"Obs_ID\",\n",
    "                  by.y = \"Obs_ID\")\n",
    "write_csv(full_data, temp_output_for_bioclim_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f86e2f-a62c-43cc-b171-1b545a6ed99d",
   "metadata": {},
   "source": [
    "## back in linux - unite data from out_temp_input_for_bioclim_path back to networks metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ead4db76-7b94-488f-b71c-736853656939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m384\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m23\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (23): Obs_ID, EcoRegion.x, BioClim_1, BioClim_2, BioClim_3, BioClim_4, B...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "bioclim_out_data = read_csv(temp_output_for_bioclim_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1ecd1882-741e-498a-b1a8-99d2cb834332",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_network_metadata = merge(relevant_network_metadata, bioclim_out_data, by.x='ID', by.y = \"Obs_ID\", all.x=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b434f41f-1d45-481a-b19d-0662a298cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = c(\"X\", \"ID\", \"network_name\")\n",
    "relevant_network_metadata = relevant_network_metadata[, !(names(relevant_network_metadata) %in% drops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "70cfec51-1402-46db-abf1-069f71305f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_networks_metadata = networks_metadata[is.na(networks_metadata$Latitude) | is.na(networks_metadata$Longitude), ]\n",
    "drop = c(\"X\", \"ID\", \"network_name\")\n",
    "rest_networks_metadata = rest_networks_metadata[ , !(names(rest_networks_metadata) %in% drops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5be51605-ff5f-4fb9-b8b3-39da06f596d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_metadata = bind_rows(relevant_network_metadata, rest_networks_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6ca66a9d-7bb1-4604-a246-d2034d319fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(networks_metadata, networks_metadata_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
