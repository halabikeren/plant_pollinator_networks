{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a12fde-fc04-47cd-85e3-685334bc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from subprocess import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc8443f-809b-4456-9ceb-b2a5d9025e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_type = \"network\"\n",
    "\n",
    "features_of_interest = {\"plant\": [\"partner.diversity\", \"d\", \"normalised.degree\", \"weighted.betweenness\", \"weighted.closeness\"],\n",
    "                        \"network\": [\"connectance\", \"NODF\", \"modularity\", \"robustness\", \"robustness_mean\", \"robustness.LL\"]}\n",
    "\n",
    "features_dir = f\"../../data/features/{features_type}/\"\n",
    "networks_dir = f\"../../data/networks/all/\"\n",
    "network_types = [\"weighted\", \"binarized_weighted\", \"binary\"]\n",
    "\n",
    "plant_classification_path = f\"../../data/ploidy_classification/plant_classification.csv\"\n",
    "network_classification_path = f\"../../data/ploidy_classification/network_classification.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcff88a3-1f7d-4731-9a4c-34c198a26607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# output_paths = 785\n",
      "# result paths = 801\n"
     ]
    }
   ],
   "source": [
    "output_paths = []\n",
    "features_paths = []\n",
    "to_submit = []\n",
    "for nt in network_types:\n",
    "    outdir = f\"{features_dir}{nt}/jobs_output/\"\n",
    "    resdir = f\"{features_dir}{nt}/features_by_network/\"\n",
    "    jobsdir = f\"{features_dir}{nt}/jobs/\"\n",
    "    l1 = [f\"{outdir}{p}\" for p in os.listdir(outdir) if p.endswith(\".out\")]\n",
    "    l2 = [f\"{resdir}{p}\" for p in os.listdir(resdir) if p.endswith(\".csv\") and \"null\" not in p]\n",
    "    output_paths += l1\n",
    "    features_paths += l2\n",
    "print(f\"# output_paths = {len(output_paths):,}\\n# result paths = {len(features_paths):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b2cb30-d385-4bfe-82b4-82df0d5924cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weighted networks for analysis = 377\n",
      "# binarized_weighted networks for analysis = 377\n",
      "# binary networks for analysis = 47\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for p in features_paths:\n",
    "    nt = p.split(\"/\")[-3]\n",
    "    df = pd.read_csv(p)\n",
    "    sd_cols = [col for col in df.columns if col.startswith(\"standardized_\")]\n",
    "    for c in sd_cols:\n",
    "        df[c] = df[c].apply(lambda x: np.nan if x < -10000 or x > 10000 else x)\n",
    "    df[\"network_type\"] = nt\n",
    "    features.append(df)\n",
    "features = pd.concat(features)\n",
    "if features_type == \"plant\":\n",
    "    if \"Plant\" not in features.columns:\n",
    "        features = features.rename(columns={\"Unnamed: 0\": \"Plant\"})\n",
    "    features.Plant = features.Plant.str.lower()\n",
    "if \"network_id\" in features.columns:\n",
    "    if features[\"network\"].dtype == str:\n",
    "        features[\"network_id\"] = features[\"network\"].str.replace(\".csv\",\"\").astype(int)\n",
    "    else:\n",
    "        features[\"network_id\"] = features[\"network\"] \n",
    "features.to_csv(f\"{features_dir}/all_features.csv\")\n",
    "for nt in network_types:\n",
    "    nt_features = features.loc[features.network_type == nt]\n",
    "    print(f\"# {nt} networks for analysis = {len(nt_features.network.unique()):,}\")\n",
    "    nt_features.to_csv(f\"{features_dir}/{nt}/features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eab496-098b-4bad-9e1f-cb302244e8f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# add classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eec1c4c-c077-480d-b912-140dd0b4541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35984/4125272318.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  features[\"network_index\"] = features.network.str.replace(\".csv\",\"\").astype(int)\n"
     ]
    }
   ],
   "source": [
    "classification_df = pd.read_csv(plant_classification_path if features_type == \"plant\" else network_classification_path)\n",
    "classification_merge_cols = [\"network_index\"] if features_type == \"network\" else [\"original_name\"]\n",
    "features_merge_cols = [\"network_index\"] if features_type == \"network\" else [\"Plant\"]\n",
    "features[\"network_index\"] = features.network.str.replace(\".csv\",\"\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44467bd-edb5-4ce7-bcb2-57ce49336d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35984/847780557.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  print(df[set(classification_df.columns)&set(df.columns)].notna().sum())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "network_type = weighted\n",
      "num_plants                   377\n",
      "is_polyploid_poly_frac       377\n",
      "num_classified               377\n",
      "num_diploids                 377\n",
      "network_index                377\n",
      "network_type                 377\n",
      "is_polyploid_missing_frac    377\n",
      "num_resolved                 377\n",
      "num_polyploids               377\n",
      "dtype: int64\n",
      "\n",
      "network_type = binarized_weighted\n",
      "num_plants                   377\n",
      "is_polyploid_poly_frac       377\n",
      "num_classified               377\n",
      "num_diploids                 377\n",
      "network_index                377\n",
      "network_type                 377\n",
      "is_polyploid_missing_frac    377\n",
      "num_resolved                 377\n",
      "num_polyploids               377\n",
      "dtype: int64\n",
      "\n",
      "network_type = binary\n",
      "num_plants                   47\n",
      "is_polyploid_poly_frac       47\n",
      "num_classified               47\n",
      "num_diploids                 47\n",
      "network_index                47\n",
      "network_type                 47\n",
      "is_polyploid_missing_frac    47\n",
      "num_resolved                 47\n",
      "num_polyploids               47\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35984/847780557.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  print(df[set(classification_df.columns)&set(df.columns)].notna().sum())\n",
      "/tmp/ipykernel_35984/847780557.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  print(df[set(classification_df.columns)&set(df.columns)].notna().sum())\n"
     ]
    }
   ],
   "source": [
    "for nt in network_types:\n",
    "    df = features.loc[features.network_type == nt]\n",
    "    relevant_classification_data = classification_df\n",
    "    if \"network_type\" in classification_df.columns:\n",
    "        relevant_classification_data = classification_df.query(f\"network_type == '{nt}'\").drop([\"network_type\"], axis=1)\n",
    "    df = df.merge(relevant_classification_data, \n",
    "                  left_on=features_merge_cols,\n",
    "                  right_on=classification_merge_cols,\n",
    "                  how=\"left\")\n",
    "    print(f\"\\nnetwork_type = {nt}\")\n",
    "    print(df[set(classification_df.columns)&set(df.columns)].notna().sum())\n",
    "    df.to_csv(f\"{features_dir}/{nt}/features_with_classification.csv\", index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5742e68f-66e6-494c-aa31-99506aa3cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network_index                1.0\n",
       "is_polyploid_poly_frac       1.0\n",
       "is_polyploid_missing_frac    1.0\n",
       "num_plants                   1.0\n",
       "num_resolved                 1.0\n",
       "num_classified               1.0\n",
       "num_polyploids               1.0\n",
       "num_diploids                 1.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "network_index                1.0\n",
       "is_polyploid_poly_frac       1.0\n",
       "is_polyploid_missing_frac    1.0\n",
       "num_plants                   1.0\n",
       "num_resolved                 1.0\n",
       "num_classified               1.0\n",
       "num_polyploids               1.0\n",
       "num_diploids                 1.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "network_index                1.0\n",
       "is_polyploid_poly_frac       1.0\n",
       "is_polyploid_missing_frac    1.0\n",
       "num_plants                   1.0\n",
       "num_resolved                 1.0\n",
       "num_classified               1.0\n",
       "num_polyploids               1.0\n",
       "num_diploids                 1.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for nt in network_types:\n",
    "    df = pd.read_csv(f\"{features_dir}/{nt}/features_with_classification.csv\")\n",
    "    df = df[[c for c in df.columns if \"Unnamed\" not in c and not \"standardized_\" in c]]\n",
    "    df = df.rename(columns={c: c.replace(\"_y\",\"\") for c in df.columns if c.endswith(\"_y\")})\n",
    "    df = df[[c for c in df.columns if not c.endswith(\"_x\")]]\n",
    "    display(df[[c for c in relevant_classification_data.columns if c in df.columns]].notna().sum() / df.shape[0])\n",
    "    df.to_csv(f\"{features_dir}/{nt}/features_with_classification.csv\", index=False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
