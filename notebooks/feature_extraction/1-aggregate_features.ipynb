{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a12fde-fc04-47cd-85e3-685334bc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc8443f-809b-4456-9ceb-b2a5d9025e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_type = \"plant\"\n",
    "\n",
    "features_of_interest = {\"plant\": [\"partner.diversity\", \"d\", \"normalised.degree\", \"weighted.betweenness\", \"weighted.closeness\"],\n",
    "                        \"network\": [\"connectance\", \"NODF\", \"modularity\", \"robustness\", \"robustness_mean\", \"robustness.LL\"]}\n",
    "\n",
    "features_dir = f\"../../data/features/{features_type}/\"\n",
    "networks_dir = f\"../../data/networks/all/\"\n",
    "network_types = [\"binary\", \"weighted\", \"binarized_weighted\"]\n",
    "\n",
    "plant_classification_path = f\"../../data/ploidy_classification/plant_classification.csv\"\n",
    "network_classification_path = f\"../../data/ploidy_classification/network_classification.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcff88a3-1f7d-4731-9a4c-34c198a26607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# output_paths = 1,255\n",
      "# result paths = 1,253\n",
      "# unsubmitted jobs = 2\n"
     ]
    }
   ],
   "source": [
    "output_paths = []\n",
    "features_paths = []\n",
    "to_submit = []\n",
    "for nt in network_types:\n",
    "    outdir = f\"{features_dir}{nt}/jobs_output/\"\n",
    "    resdir = f\"{features_dir}{nt}/features_by_network/\"\n",
    "    jobsdir = f\"{features_dir}{nt}/jobs/\"\n",
    "    unsubmitted = set([p.replace(\".sh\",\"\") for p in os.listdir(jobsdir)])-set([p.replace(\".out\",\"\") for p in os.listdir(outdir)])\n",
    "    to_submit += [f\"{jobsdir}{j}.sh\" for j in unsubmitted]\n",
    "    l1 = [f\"{outdir}{p}\" for p in os.listdir(outdir) if p.endswith(\".out\")]\n",
    "    l2 = [f\"{resdir}{p}\" for p in os.listdir(resdir) if p.endswith(\".csv\") and \"null\" not in p]\n",
    "    output_paths += l1\n",
    "    features_paths += l2\n",
    "print(f\"# output_paths = {len(output_paths):,}\\n# result paths = {len(features_paths):,}\")\n",
    "print(f\"# unsubmitted jobs = {len(to_submit):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c46555f9-fb8a-450c-a399-9fa1b45201c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from subprocess import *\n",
    "from collections import defaultdict\n",
    "\n",
    "job_path_regex = re.compile(\"Submit_arguments\\s=.*?(\\/.*?)\\s\")\n",
    "\n",
    "jobs_log = str(Popen([\"qstat\", \"-u\", \"halabikeren\"], stdout=PIPE).communicate()[0]).split(\"\\\\n\")[5:]\n",
    "jobs_ids = [item.split(\".\")[0] for item in jobs_log if len(item.split(\".\")[0]) > 1]\n",
    "job_path_to_id = defaultdict(list)\n",
    "for job_id in jobs_ids:\n",
    "    try:\n",
    "        job_log = str(Popen([\"qstat\", \"-f\", job_id], stdout=PIPE).communicate()[0]).replace(\"\\\\n\",\"\").replace(\"\\\\t\",\"\")\n",
    "        job_path = job_path_regex.search(job_log).group(1)\n",
    "        job_path_to_id[job_path].append(job_id)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00fe7608-5545-437a-b98f-e09a4fb5e60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/features/plant/weighted/jobs/536.sh\n",
      "../../data/features/plant/binarized_weighted/jobs/536.sh\n"
     ]
    }
   ],
   "source": [
    "for jp in to_submit:\n",
    "    if jp not in job_path_to_id:\n",
    "        print(jp)\n",
    "        res=os.system(f\"qsub -q itay_75 {jp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "313d05b5-cca2-48bc-9aa2-fd3a99f6de47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# failed by unknown reason = 0\n",
      "# failed by memory = 2\n",
      "# failed by size = 0\n",
      "jobs_to_rerun = 0\n"
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "failed_mem = []\n",
    "failed_too_small = []\n",
    "to_rerun = []\n",
    "for p in output_paths:\n",
    "    res_path = p.replace(\"jobs_output\", \"features_by_network\").replace(\".out\", \"_features.csv\")\n",
    "    job_path = p.replace(\"jobs_output\", \"jobs\").replace(\".out\", \".sh\")\n",
    "    \n",
    "    if job_path in job_path_to_id:\n",
    "        continue\n",
    "\n",
    "    with open(p, \"r\") as f:\n",
    "        c=f.read()\n",
    "    if \"duration\" not in c and not os.path.exists(res_path):\n",
    "        failed.append(p)\n",
    "    if \"PBS: job killed: mem\" in c:\n",
    "        failed_mem.append(p)\n",
    "    if \"too small\" in c:\n",
    "        failed_too_small.append(p)\n",
    "    if \"does not exist\" in c:\n",
    "        to_rerun.append(p)\n",
    "failed_other = set(failed)-set(failed_mem)-set(failed_too_small)-set(to_rerun)       \n",
    "print(f\"# failed by unknown reason = {len(failed_other):,}\\n# failed by memory = {len(failed_mem):,}\\n# failed by size = {len(failed_too_small):,}\\njobs_to_rerun = {len(to_rerun)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ff0e59b-ebdf-42c6-aeaf-8510e162cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# missing output = 4\n"
     ]
    }
   ],
   "source": [
    "missing = {}\n",
    "nmissing = 0\n",
    "for nt in network_types:\n",
    "    networks = [p.replace(\".csv\", \"\") for p in os.listdir(f\"{networks_dir}{nt}/\") if p.endswith(\".csv\")]\n",
    "    results_dir = f\"{features_dir}{nt}/features_by_network/\"\n",
    "    resulting_networks = [p.replace(\"_features.csv\",\"\") for p in os.listdir(results_dir) if \"null\" not in p and p.endswith(\".csv\")]\n",
    "    missing[nt] = set(networks)-set(resulting_networks)\n",
    "    nmissing += len(missing[nt])\n",
    "print(f\"# missing output = {nmissing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cebc48d4-82d7-4fc6-ab12-24f71981ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': set(),\n",
       " 'weighted': {'290', '536'},\n",
       " 'binarized_weighted': {'290', '536'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49843a84-e093-4b50-8fc8-8c2f5e0bd122",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nt in missing:\n",
    "    for m in missing[nt]:\n",
    "        jp = f\"{features_dir}{nt}/jobs/{m}.sh\"\n",
    "        with open(jp, \"r\") as f:\n",
    "            c=f.read()\n",
    "        c=c.replace(\"/_features/\", \"/features/\").replace(\"/features/_by_network/\", \"/features_by_network/\")\n",
    "        with open(jp, \"w\") as f:\n",
    "            f.write(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "338f1cab-394c-4a12-ba58-b36bb15cc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nt in missing:\n",
    "    for m in missing[nt]:\n",
    "        jp = f\"{features_dir}{nt}/jobs/{m}.sh\"\n",
    "        res = os.system(f\"qsub -q itay_75 {jp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d2a7961-051f-4c39-a65e-2802d2ec6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/features/plant/weighted/jobs/290.sh\n",
      "../../data/features/plant/binarized_weighted/jobs/290.sh\n"
     ]
    }
   ],
   "source": [
    "for jop in failed_mem:\n",
    "    jp = jop.replace(\"jobs_output\", \"jobs\").replace(\".out\", \".sh\")\n",
    "    with open(jp, \"r\") as f:\n",
    "        c=f.read()\n",
    "    c=c.replace(\"/features\", \"/_features/\").replace(\"15gb\", \"30gb\").replace(\"50gb\", \"80gb\").replace(\"30gb\", \"50gb\").replace(\"20gb\", \"30gb\").replace(\"15gb\", \"20gb\").replace(\"10gb\", \"15gb\").replace(\"4gb\", \"10gb\")\n",
    "    with open(jp, \"w\") as f:\n",
    "        f.write(c)\n",
    "    if os.path.exists(jop):\n",
    "        os.remove(jop)\n",
    "    # res=os.system(f\"qsub -q itay_75 {jp}\")\n",
    "    print(jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7868b4b7-c57e-415c-a19a-7da986ad60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in to_rerun:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "    jp = f.replace(\"jobs_output\", \"jobs\").replace(\".out\", \".sh\")\n",
    "    res = os.system(f\"qsub -q itay_75 {jp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92b2cb30-d385-4bfe-82b4-82df0d5924cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18030/35926450.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  features[\"network\"] = features[\"network\"].str.replace(\".csv\",\"\").astype(int)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for p in features_paths:\n",
    "    nt = p.split(\"/\")[-3]\n",
    "    df = pd.read_csv(p)\n",
    "    sd_cols = [col for col in df.columns if col.startswith(\"standardized_\")]\n",
    "    for c in sd_cols:\n",
    "        df[c] = df[c].apply(lambda x: np.nan if x < -10000 or x > 10000 else x)\n",
    "    df[\"network_type\"] = nt\n",
    "    features.append(df)\n",
    "features = pd.concat(features)\n",
    "features = features.rename(columns={\"Unnamed: 0\": \"Plant\"})\n",
    "if \"network\" in features.columns:\n",
    "    features[\"network\"] = features[\"network\"].str.replace(\".csv\",\"\").astype(int)\n",
    "features.to_csv(f\"{features_dir}/all_features.csv\")\n",
    "for nt in network_types:\n",
    "    features.loc[features.network_type == nt].to_csv(f\"{features_dir}/{nt}/features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eab496-098b-4bad-9e1f-cb302244e8f1",
   "metadata": {},
   "source": [
    "# add classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0eec1c4c-c077-480d-b912-140dd0b4541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(plant_classification_path if features_type == \"plant\" else network_classification_path)\n",
    "classification_merge_cols = [\"network_type\", \"network_id\"] if features_type == \"network\" else [\"original_name\"]\n",
    "features_merge_cols = [\"network_type\", \"network\"] if features_type == \"network\" else [\"Plant\"]\n",
    "classification_cols = [\"conservative_is_polyploid_poly_frac\",\"conservative_is_polyploid_missing_frac\",\"num_plants\", \"num_resolved\",\"num_classified\",\"num_polyploids\",\"num_diploids\"] if features_type == \"network\" else [\"conservative_is_polyploid_by_resolved\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b44467bd-edb5-4ce7-bcb2-57ce49336d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nt in network_types:\n",
    "    df = features.loc[features.network_type == nt]\n",
    "    df = df.merge(classification_df[classification_merge_cols+classification_cols], \n",
    "                  left_on=features_merge_cols,\n",
    "                  right_on=classification_merge_cols,\n",
    "                  how=\"left\")\n",
    "    df.to_csv(f\"{features_dir}/{nt}/features_with_classification.csv\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
